------------ Options -------------
add_local: False
add_non_visual: False
alpha: 20.0
att_iou_thd: 0.5
att_loss_type: lse
att_weight: 0.1
bsz: 16
clip: 10.0
cls_encoder_kernel_size: 5
cls_encoder_n_blocks: 1
cls_encoder_n_conv: 2
cls_encoder_n_heads: 0
debug: False
device: 0
device_ids: [0, 1]
drop_topk: 0
dropout: 0.1
embedding_size: 768
eval_object_vocab_path: /dev/shm/tvqa_plus_stage_features/eval_object_vocab.json
extra_span_length: 3
frm_cnt_path: /dev/shm/tvqa_plus_stage_features/frm_cnt_cache.json
glove_path: data/glove.6B.300d.txt
hard_negative_start: 100
hsz: 128
inference_mode: False
input_encoder_kernel_size: 7
input_encoder_n_blocks: 1
input_encoder_n_conv: 2
input_encoder_n_heads: 0
input_streams: ['sub', 'vfeat', 'vcpt']
learn_word_embedding: False
log_freq: 800
lr: 0.001
margin: 0.1
max_a_l: 15
max_es_cnt: 5
max_q_l: 20
max_qa_l: 40
max_sub_l: 50
max_vcpt_l: 300
max_vid_l: 300
n_epoch: 10
negative_pool_size: 0
no_core_driver: False
no_glove: False
non_visual: 0
num_hard: 2
num_negatives: 2
num_region: 25
num_workers: 16
qa_bert_path: /dev/shm/tvqa_plus_stage_features/bbt_qa_s_tokenized_bert_sub_qa_tuned_new_qid.h5
results_dir: results/results_2020_12_04_00_32_55
results_dir_base: results/results
resume: 
scale: 10.0
seed: 2018
sub_bert_path: /dev/shm/tvqa_plus_stage_features/bbt_sub_s_tokenized_bert_sub_qa_tuned.h5
sub_path: /dev/shm/tvqa_plus_stage_features/tvqa_plus_subtitles.json
t_iter: 0
t_layer_type: linear
test_bsz: 16
test_path: /dev/shm/tvqa_plus_stage_features/tvqa_plus_test_preprocessed_no_anno.json
train_path: /dev/shm/tvqa_plus_stage_features/tvqa_plus_train_preprocessed.json
ts_weight: 0.5
use_sup_att: True
valid_path: /dev/shm/tvqa_plus_stage_features/tvqa_plus_valid_preprocessed.json
vcpt_path: /dev/shm/tvqa_plus_stage_features/tvqa_bbt_frcn_vg_hq_20_100.json
vfeat_path: /dev/shm/tvqa_plus_stage_features/tvqa_bbt_bottom_up_pool5_hq_20_100_pca.h5
vfeat_size: 300
vfeat_type: None
vocab_size: 0
wd: 3e-07
word2idx_path: /dev/shm/tvqa_plus_stage_features/word2idx.json
-------------- End ----------------
[#GPUs]  Using 2 / Available 4 
Activate sub branch
Activate vid branch

Loading cache ...
Parameter Count: all 5,814,669; trainable 5,814,669
CUDA enabled.
Use multi GPU [0, 1]
Epoch 00 [Train] acc 0.0000 loss 0.0000 loss_att 0.0000 loss_ts 0.0000 loss_cls 0.0000
Epoch 00 [Val] acc 0.2101 loss 6.0361
Epoch 00 [Train] acc 0.3859 loss 5.4580 loss_att 2.1658 loss_ts 1.8403 loss_cls 1.4519
Epoch 00 [Val] acc 0.4226 loss 5.2832
Epoch 01 [Train] acc 0.0000 loss 0.0000 loss_att 0.0000 loss_ts 0.0000 loss_cls 0.0000
Epoch 01 [Val] acc 0.4504 loss 5.1949
Epoch 01 [Train] acc 0.4473 loss 5.2324 loss_att 2.0565 loss_ts 1.8386 loss_cls 1.3373
Epoch 01 [Val] acc 0.4528 loss 5.1291
Epoch 02 [Train] acc 0.0000 loss 0.0000 loss_att 0.0000 loss_ts 0.0000 loss_cls 0.0000
Epoch 02 [Val] acc 0.5340 loss 4.9358
Epoch 02 [Train] acc 0.5584 loss 4.9193 loss_att 2.0048 loss_ts 1.8077 loss_cls 1.1068
Epoch 02 [Val] acc 0.6023 loss 4.7593
Epoch 03 [Train] acc 0.0000 loss 0.0000 loss_att 0.0000 loss_ts 0.0000 loss_cls 0.0000
Epoch 03 [Val] acc 0.6192 loss 4.6853
Epoch 03 [Train] acc 0.6495 loss 4.6787 loss_att 1.9771 loss_ts 1.7947 loss_cls 0.9068
Epoch 03 [Val] acc 0.6473 loss 4.6183
Epoch 04 [Train] acc 0.0000 loss 0.0000 loss_att 0.0000 loss_ts 0.0000 loss_cls 0.0000
Epoch 04 [Val] acc 0.6463 loss 4.6223
Epoch 04 [Train] acc 0.6805 loss 4.5776 loss_att 1.9685 loss_ts 1.7869 loss_cls 0.8222
Epoch 04 [Val] acc 0.6473 loss 4.6071
Epoch 05 [Train] acc 0.0000 loss 0.0000 loss_att 0.0000 loss_ts 0.0000 loss_cls 0.0000
Epoch 05 [Val] acc 0.6526 loss 4.5962
Epoch 05 [Train] acc 0.7151 loss 4.5041 loss_att 1.9726 loss_ts 1.7858 loss_cls 0.7458
Epoch 05 [Val] acc 0.6424 loss 4.6299
Epoch 06 [Train] acc 0.0000 loss 0.0000 loss_att 0.0000 loss_ts 0.0000 loss_cls 0.0000
Epoch 06 [Val] acc 0.6616 loss 4.5665
Epoch 06 [Train] acc 0.7334 loss 4.3887 loss_att 1.9222 loss_ts 1.7815 loss_cls 0.6850
Epoch 06 [Val] acc 0.6520 loss 4.6094
